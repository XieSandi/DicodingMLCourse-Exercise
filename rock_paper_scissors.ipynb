{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " rock paper scissors.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWITWlKwLWuUdO/a+QMbMZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XieSandi/DicodingMLCourse-Exercise/blob/main/rock_paper_scissors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xbq7BSnjuq2"
      },
      "source": [
        "**Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c06bcshOI81R"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya75BD5vKPgB"
      },
      "source": [
        "import zipfile,os,shutil\n",
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrnncFlhkGO5"
      },
      "source": [
        "**Installing Library / Package**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugs03TYxjXs5"
      },
      "source": [
        "pip install split-folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbhOCUPBkU-y"
      },
      "source": [
        "**Importing Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5gjNfg9jnct"
      },
      "source": [
        "import tensorflow as tf\n",
        "import split-folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NemMI8XMT3-Q"
      },
      "source": [
        "#creating new folder\n",
        "train_path = \"/tmp/rockpaperscissors/train\"\n",
        "\n",
        "try:\n",
        "    os.mkdir(train_path)\n",
        "except OSError:\n",
        "    print (\"Waduh !\")\n",
        "else:\n",
        "    print (\"Mantap !\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HzJL21DRnvy"
      },
      "source": [
        "try:\n",
        "    #Moving Folder into train\n",
        "    shutil.move(\"/tmp/rockpaperscissors/paper\", \"/tmp/rockpaperscissors/train\")\n",
        "    shutil.move(\"/tmp/rockpaperscissors/rock\", \"/tmp/rockpaperscissors/train\")\n",
        "    shutil.move(\"/tmp/rockpaperscissors/scissors\", \"/tmp/rockpaperscissors/train\")\n",
        "\n",
        "    #Renaming folder info validation\n",
        "    os.rename(\"/tmp/rockpaperscissors/rps-cv-images\", \"/tmp/rockpaperscissors/validation\")\n",
        "except OSError:\n",
        "    print (\"Waduh !\")\n",
        "else:\n",
        "    print (\"Mantap !\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbnIkn82NHX-"
      },
      "source": [
        "base_train_dir = '/tmp/rockpaperscissors/train'\n",
        "base_validation_dir ='/tmp/rockpaperscissors/validation'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_qZrKm5NWj_"
      },
      "source": [
        "# training\n",
        "train_paper_dir = os.path.join(base_train_dir, 'paper')\n",
        "train_rock_dir = os.path.join(base_train_dir, 'rock')\n",
        "train_scissor_dir = os.path.join(base_train_dir, 'scissor')\n",
        " \n",
        "#validating\n",
        "validation_paper_dir = os.path.join(base_validation_dir, 'paper')\n",
        "validation_rock_dir = os.path.join(base_validation_dir, 'rock')\n",
        "validation_scissor_dir = os.path.join(base_validation_dir, 'scissor')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWVoGHIUO1Fn"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')\n",
        " \n",
        "test_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PPbywqFPHkR"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        base_train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=4,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        base_validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=4,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEO-0_CIW8FU"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aXQR_WiW-i3"
      },
      "source": [
        "# compile model with 'adam' optimizer loss function 'binary_crossentropy' \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# latih model with model.fit \n",
        "model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=5,\n",
        "      epochs=10,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=5,\n",
        "      verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx8oSS8gYRUd"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "uploaded = files.upload()\n",
        " \n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  \n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  #String output template\n",
        "  paper     = \"[[1. 0. 0.]]\"\n",
        "  rock      = \"[[0. 1. 0.]]\"\n",
        "  scissors  = \"[[0. 0. 1.]]\"\n",
        "  \n",
        "  #convert numpy array into string\n",
        "  result = np.array_str(classes) \n",
        "  \n",
        "  \n",
        "  print('\\n')\n",
        "  print('Predict RESULT')\n",
        "  print(fn)\n",
        "  print(result)\n",
        "\n",
        "\n",
        "  #Changing result into human language\n",
        "  if result == paper :\n",
        "     print(\"paper\")\n",
        "  elif result == rock :\n",
        "     print(\"rock\")\n",
        "  elif result == scissors :\n",
        "     print(\"scissors\")\n",
        "  else :\n",
        "     print(\"[[%PAPER. %ROCK. %SCISSORS]]\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}